Week  1 Lecture Notes
Points  of  clarification and fun facts re: video lectures
L2: Computational Neuroscience: Descriptive Models
- Slide:  An  Example:  Models  of  “Receptive  Fields”
o If  you want  to  see more  examples  of  Hubel and Wiesel’s  
experiments,  check out:
http://www.youtube.com/watch?v=Cw5PKV9Rj3o
o Converting  the electrical  activity  of  neurons to  an  audio signal  is  a 
common  practice  in  experimental  neuroscience, as  it  allows  
researchers to  easily  and immediately tell  when  a neuron  is  active. 
In  a typical setup,  each  “pop” in  the signal  is  an  action  potential—
when  neurons fire  many  action  potentials  per second, the sound 
resembles loud  static.
- Slide:  Descriptive Model of  Receptive Fields
o When  we  talk about  center-on,  surround-off, or  center-off, 
surround-on cells,  remember  that  we’re not talking about the 
center  and “surround”  of  the entire  retina, but rather  only  the 
small portion of  it  associated  with  that  cell, i.e., each  cell  generally 
cares only  about what’s  going on  in  a very  small region  of  the 
visual  field,  and these regions tend  to  be  on  the order of  a degree  
or  two (though the size  of  the RF  depends on  its location).  As  a 
rough approximation,  you can think of  many  cells’ RFs  “tiling”  the 
visual  scene (in reality,  there is  quite a bit of  overlap,  and different 
cells may have  different color-tuning  properties, etc.).  Smaller RFs 
near  the center  of  the visual  field (the  fovea)  lead  to  “higher 
resolution” there during  the daytime.
L3: Computational Neuroscience: Mechanistic and Interpretive  Models
- Slide:  III.  Interpretive  Model of  Receptive Fields  (oriented bars)
o Again,  remember  that  these oriented  bars  do  not span  the entire  
retina, but only  a small portion of  it  (if they  spanned the entire  
retina, you’d only  be  able  to  make  asterisk-like images).  Because of  
this, you can linearly  combine them  to  make  an  enormous  variety 
of  images. For example,  can you think of  the combination of  RFs 
needed  to  make  a square? A polygon?  A duck?
- Slide:  III.  Interpretive  Model of  Receptive Fields  (RFs  from  natural 
images)
o It’s  worth emphasizing that  the RFs on  this  slide are learned only  
from  the set of  natural images  and do  not depend  at  all on  any 
experimental  data. The algorithm that  learns  them  simply  chooses 
the ideal set of  RFs for natural images  subject to  two constraints 
(1. Efficient representation  (sparse coding)—representing  images  
using as  few components  as  possible, 2.  Faithful  representation—
accurate  representation  of  important image features).  The fact  
that  the RFs found by  the algorithm match the RFs observed  
experimentally  is  very  cool, suggesting  that  perhaps efficient and 
faithful  representation  were  also  the optimization  criteria  “used”
during  the evolution of  V1.
L 4:  The Electrical  Personality of  Neurons
- Slide:  The Idealized Neuron
o In  the initial EPSP  plots,  the x-axis  is  time, and the y-axis  is  
electrical  potential (voltage).
o It  is  important to  note  that  an  action  potential is  not just  the sum 
of  several EPSP’s, but is  rather  an  active  signal  generated by  the 
sum of  the EPSP’s  crossing  a threshold.  Usually this  threshold is  
around  30mV  above the neuron’s  resting potential.
- Slide:  The Electrical  Personality of  a Neuron  (ion  channels)
o While pumps and other components  are indeed  needed  to  model 
the cell  as  a complete  circuit that  obeys Kirchoff’s  laws, etc., for our 
purposes, we  can just  think of  pumps as  having  the sole  purpose of  
maintaining the steady-state  intra- and  extracellular ion 
concentrations. Channels, on  the other hand  are just  gates that,
when  opened, allow ions  to  flow  down  their concentration 
gradients.
o It’s  worth noting  that  the properties  of  an  action  potential can’t be  
derived from  a simple  application of  Ohm’s law.  This  is  because 
current,  voltage,  and membrane  conductance all change  as  a
function  of  time. Instead,  an  action  potential is  described by a  set 
of  differential  equations that  model how these variables change  
with  time. Hodgkin and Huxley  were  the first to  formulate and 
present a solution  to  this  set of  equations,  as  will  be  discussed in  
later lectures.
- Slide:  Active  Wiring: Myelination of  Axons
o Lossless  signal  propagation is  very  important,  as  some  action  
potentials  have  to  travel  very  long  distances (think  of  the axons 
that  reach down  to  your toes,  for example). If  signal  propagation 
were  based on  passive changes in  membrane  potential,  then  
signals would dissipate much  too fast  for information to  be  
conveyed  over  long  distances.
L 5:  Making  Connections:  Synapses
- Slide:  Long  Term  Depression  (LTD)
o Depending on  the specific  situation,  sometimes it  can be  useful  to  
have  LTP,  and sometimes it  can be  useful  to  have  LTD.  For 
example,  LTP can be  used  to  strengthen  connections between 
circuits  that  fire  synchronously so  as  to  increase  their chance  of  
firing  synchronously in  the future. LTD on  the other hand, could be  
used  to  separate  circuits  that  normally  operate independently.  
Another type  of  synaptic  depression  occurs  in  homeostatic 
plasticity, in  which networks  of  neurons change  their synaptic  
strengths over  long  time  scales—it has been  hypothesized  that  
this  occurs  to  control the average firing  rate  of  a network.  The 
mechanisms  and computations  related to  synaptic  plasticity  is  an  
active  area  of  study.
